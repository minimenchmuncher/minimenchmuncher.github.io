---
title: Lists of DTOs
date: 2017-08-15T23:00:00Z
layout: post
path: "/dto-lists/"
tags:
  - R
---

Say you have your DAL set up, and you have some kind of data structure based on lists for your DTOs<sup>[1](#fn1)</sup>. Good for you, well done! Sometimes, you'll see that the DTOs that you're using are very stand-alone, that is, you only need a single instance of a class<sup>[2](#fn2)</sup>. But more often than not you need multiple instances of a class, and at that, closely related ones. What do you do with them?

In C-based languages, you might think of your data object being some kind of struct, creating arrays of structs is a pretty trivial exercise. In R this is... kind of the case. The thing is that R has so much built-in structure for dealing with data structures that *not* taking advantage of some of them just seems like a shame.

There are a few options that I've come across and have used all of them, for one reason or another.

### Leaving Well Enough Alone

Say you have 2 instances of a class `foo`:

```R
foo1 <- structure(list(x = 2, y = "a"), class = "foo")
foo2 <- structure(list(x = 5, y = "b"), class = "foo")
```

And you'd just *love* to have some data structure that combined `foo1` and `foo2`. Your best bet - just do

```R
foos <- list(foo1, foo2)
```

I mean, why not. You can always use `lapply` to access the attributes you need, it's a nice, compact form, and will require no modifications to your data organization or anything, regardless of how the data are organized. Huge upsides.

Your downsides are that `foos` looks different from the `foo` class. You could still say that `foos` should be the same class as `foo`, but your method dispatch can get messy. You could solve this by having a `foos` class, and associated methods, but if they're the same methods as `foo`, you're really not solving anything - just moving the confusion into your methods instead of the data structure.

Still, it's a reasonably good way or organizing things, plenty of the time. I would recommend implementing

```R
c.foo <- function(...) structure(list(...), class = "foo") # or class "foos"
```

Why? Like an idiot, I've spent hours looking for bugs associated with combining DTOs using `c`, wondering why the output doesn't work the way I'd expect. Just give yourself this one, for your own sanity<sup>[3](#fn3)</sup>.

### Data Frames

You'll note that `$x` and `$y` in the two above objects are of the same class (numeric, character), and all of the elements/attributes are of length 1. That looks like it could very easily be a data frame. So let's implement a `data.frame` method:

```R
as.data.frame.foo <- function(x, ...) {
  foos <- list(x, ...)
  xs <- unlist(lapply(foos, getElement, "x"))
  ys <- unlist(lapply(foos, getElement, "y"))
  data.frame(x = xs, y = ys)
}
```

You can think of this as "stacking" your DTOs. This above function is one way to do it - you can also make your individual DTOs into data frames, and then actually stack them with `rbind` (I wouldn't though, the above example has more flexibility and is generally faster I've found).

Data frames have huge advantages to them. Suddenly, you have access to the wide range of data manipulations that you get with data frames (think tidyr, dplyr, etc). I very frequently go in this direction.

Only problem is, what happens when you have an element that's not flat - say your `$x` attribute has length greater than 1? Well maybe that's not so bad...

```R
as.data.frame.foo <- function(x, ...) {
  input_names <- c(deparse(substitute(x)))
  foos <- list(x, ...)
  xs <- unlist(lapply(foos, function(i) {
    vec <- getElement(i, "x")
    paste(vec, collapse = ";")
    }))
  ys <- unlist(lapply(foos, getElement, "y"))
  data.frame(x = xs, y = ys)
}
```

If your data frame is long and wide, and this only happens to one or two columns, that can be fine. For example, if your dtos themselves have tags, they may appear as a character vector already, and you never really have any logic to deal with them separately. And if you do (like with tags), it's nothing a regex can't cure.

But the above example does illustrate a problem. Suddenly you lost the ability to do vectorized math on the `$x` column.

This is fixable in another way, create a copy of that row for each tag element you have, and keep the other attributes the same. This is much more in concert with the "tidy" data concept, but if you have multiple elements that have longer lengths, the number of copied rows you get starts getting really large.

### Vectors

Way on the other end of the spectrum of niceness, you could just coerce everything to a character:

```R
as.character.foo <- function(x, ...) {
  foos <- list(x, ...)
  unlist(lapply(foos, function(i) {
    sprintf("x:%0.0f;y:%s", i$x, i$y)
  }))
}
```

Well, this way you have a vector! Okay, this example is a little silly, but if your data structure is hierarchical, if plenty of your data are characters anyway, and there aren't too many attributes, this can be a pretty nifty way to store data. Think about the differences between `POSIXlt` and `POSIXct`. `POSIXlt` is a list, `POSIXct` is a single number that looks like a character (Time works this way since it's continuous, but your data may not be). You can do all the subsetting and selecting variables using functions and regexes. You'll see a lot of `lapply`s and `vapplys` in your code if you do this.

The main benefit of stashing all of your data as character key-value pairs is that your data types get democratized - everything is the same. Everything is a character, and your dto list gets flattenend into a vector. This can be a real life-saver in situations when you don't know what data type your data are coming to you as. And as much as you should try to avoid those kinds of situations, sometimes you can't. And those times, you do something like this.

There are obviously downsides. Querying and subsetting your data gets really annoying and tricky. You have to make sure that your separation characters (here, ":" and ";") aren't used elsewhere in your data. Size can also be a factor, as your memory needs will grow pretty quickly dealing only with characters. Also your functions will be slow in subsetting and teasing out particular values. I could go on, but I think you get the point.

### Going nuts

When the above situation happened to me I started implementing methods in C++ and letting my query functions live in a complied form. Then I realized, why do that - so long as the strings are formatted right, there are already tools for doing that. And those tools are things like a JSON or XML parser. These are mature tools using compiled code that will get the job done (reasonably) fast.

But if you're going down that rabbit hole, I would start to strongly consider why. I'd only go this route if your data *must* be in some common format (character), and is sufficiently hierarchical. But in most cases, coercing your data into characters while keeping it a list is a much better option<sup>[4](#fn4)</sup>.

### Conclusion

Using an unaltered list can be convenient and easy on the data side, but can lead to some issues when it comes time to actually analyze the data. On the other hand, given the structure of your data, using a data frame may not be a great idea either. It comes down to how hierarchical your data are, how much you want to deal with flattening them, how you'll end up querying the data and what types of queries you'll want to do.




<a name="fn1">1:</a> For these purposes, let's say it doesn't matter if you're using lists or more tightly controlled S4 objects. Major difference is instead of using `getElement()`, you'd use `slot()`. The general concepts are the same in any case.

<a name="fn2">2:</a> Plenty of R users will bristle at needing to do this. See previous posts as to why this may still be a good idea. Or, if you're too busy to do that, just suffice to say classes can still help you do a lot of things, they can enable method dispatch, and classes are a nifty way of versioning. Sometimes my code gets littered with classes that never get implemented, or that do have implementations that never get actually used in the analysis. This is called "being forward thinking", or for orphaned classes "backwards compatability". As long as you're clear in your code what's what, using comments for example, this can be a very good thing within reason.

<a name="fn3">3:</a> If you're curious as to what happens if you *do* use `c`, you'll get a List of 4 in this situation, with 2 `$x`'s and 2 `$y`'s. Is this what you want? No, it's not. And if it is, you and I need to have a talk.

<a name="fn4">4:</a> Besides, oftentimes, the first thing that I do when I'm presented with a JSON or XML document is just convert it into a list that I can work with in R.
